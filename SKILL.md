---
name: scientific-skills-complete
description: "Comprehensive scientific computing skill enabling Claude to work with 83+ scientific packages, databases, and methodologies across bioinformatics, cheminformatics, materials science, and data analysis. Includes 25 databases (PubMed, ChEMBL, UniProt), 50 packages (BioPython, RDKit, Scanpy), and scientific thinking frameworks."
---

# Scientific Skills - Complete Package

## Overview

This skill transforms Claude into an AI Scientist capable of working with specialized scientific libraries, databases, and methodologies across multiple scientific domains:

- üß¨ **Bioinformatics & Genomics** - Single-cell analysis, genomics, proteomics
- üß™ **Cheminformatics & Drug Discovery** - Molecular design, virtual screening, property prediction
- üî¨ **Proteomics & Mass Spectrometry** - Protein analysis, metabolomics
- ü§ñ **Machine Learning & AI** - Deep learning, statistical modeling, visualization
- üîÆ **Materials Science & Chemistry** - Crystal structures, computational chemistry
- üìä **Data Analysis & Visualization** - Statistical analysis, publication-quality figures
- üè• **Healthcare & Clinical** - Medical imaging, clinical data, healthcare AI

## Core Capabilities

### 1. Scientific Databases (25 databases)

Access and query major scientific databases programmatically:

**Biomedical & Literature:**
- **PubMed** - 35M+ biomedical literature citations
- **bioRxiv/medRxiv** - Preprint servers for life sciences
- **NCBI Gene** - Gene-specific information and annotations
- **GEO** - Gene Expression Omnibus functional genomics data

**Protein & Genomics:**
- **UniProt** - Protein sequences and functional information
- **AlphaFold DB** - 200M+ AI-predicted protein structures
- **PDB** - Experimental protein structures
- **Ensembl** - Genome browser with annotations
- **ENA** - European Nucleotide Archive

**Chemistry & Drug Discovery:**
- **PubChem** - 110M+ chemical compounds
- **ChEMBL** - Bioactive molecules with drug-like properties
- **ZINC** - Commercially-available compounds for screening
- **KEGG** - Biological pathways and molecular interactions
- **Reactome** - Curated biological pathways

**Clinical & Genetics:**
- **ClinicalTrials.gov** - Global clinical studies registry
- **ClinVar** - Genomic variants and clinical significance
- **COSMIC** - Catalogue of somatic mutations in cancer
- **ClinPGx** - Clinical pharmacogenomics
- **GWAS Catalog** - Genome-wide association studies
- **Open Targets** - Therapeutic target validation

**Metabolomics:**
- **HMDB** - Human Metabolome Database
- **Metabolomics Workbench** - NIH metabolomics data repository

**Other:**
- **STRING** - Protein-protein interaction networks
- **FDA Databases** - Drug approvals, adverse events, recalls
- **USPTO** - Patent and trademark search

### 2. Scientific Packages (50 packages)

**Bioinformatics & Genomics (12 packages):**
- **BioPython** - Sequence analysis, file parsing, alignment
- **Scanpy** - Single-cell RNA-seq analysis
- **AnnData** - Annotated data matrices for genomics
- **scvi-tools** - Deep generative models for single-cell
- **Cellxgene Census** - Standardized single-cell data corpus
- **PyDESeq2** - Differential gene expression analysis
- **pysam** - SAM/BAM/VCF file manipulation
- **gget** - Efficient genomic data queries
- **Arboreto** - Gene regulatory network inference
- **deepTools** - NGS data analysis tools
- **FlowIO** - Flow cytometry data handling
- **BioServices** - Access to biological web services

**Cheminformatics & Drug Discovery (8 packages):**
- **RDKit** - Molecular manipulation and property calculation
- **DeepChem** - Deep learning for chemistry
- **DiffDock** - Molecular docking with diffusion models
- **Datamol** - Molecular manipulation utilities
- **MedChem** - Medicinal chemistry analysis
- **Molfeat** - Molecular featurization
- **PyTDC** - Therapeutics Data Commons access
- **TorchDrug** - Graph neural networks for drug discovery

**Proteomics & Mass Spectrometry (2 packages):**
- **pyOpenMS** - Mass spectrometry data analysis
- **matchms** - Spectral similarity and matching

**Machine Learning & Deep Learning (10 packages):**
- **PyTorch Lightning** - High-level PyTorch framework
- **scikit-learn** - Classical machine learning algorithms
- **scikit-survival** - Survival analysis and time-to-event
- **Transformers** - Pre-trained models and NLP
- **Torch Geometric** - Graph neural networks
- **SHAP** - Model interpretability and feature importance
- **PyMC** - Bayesian statistical modeling
- **PyMOO** - Multi-objective optimization
- **statsmodels** - Statistical tests and models
- **UMAP-learn** - Dimensionality reduction

**Materials Science & Chemistry (3 packages):**
- **Pymatgen** - Materials analysis and crystal structures
- **COBRApy** - Constraint-based metabolic modeling
- **Astropy** - Astronomy and astrophysics tools

**Data Analysis & Visualization (6 packages):**
- **Matplotlib** - Publication-quality figures
- **Seaborn** - Statistical data visualization
- **Polars** - Fast DataFrame operations
- **Dask** - Parallel computing and big data
- **ReportLab** - PDF generation and reporting
- **SimPy** - Discrete-event simulation

**Healthcare & Medical (3 packages):**
- **pydicom** - DICOM medical imaging format
- **PyHealth** - Healthcare AI and clinical data
- **scikit-survival** - Survival analysis for clinical outcomes

**Additional Specialized Tools (6 packages):**
- **BIOMNI** - Multi-omics network integration
- **ETE Toolkit** - Phylogenetic tree analysis
- **Paper-2-Web** - Academic paper presentation tools
- **scikit-bio** - Biological sequence analysis
- **ToolUniverse** - 600+ scientific tool ecosystem
- **Zarr** - Cloud-optimized array storage

### 3. Scientific Integrations (6 platforms)

Integrate with laboratory and research platforms:

- **Benchling** - R&D platform and LIMS workflows
- **DNAnexus** - Cloud genomics platform
- **LabArchives** - Electronic Lab Notebook (ELN)
- **LatchBio** - Bioinformatics workflow platform
- **OMERO** - Microscopy image data management
- **Opentrons** - Laboratory automation protocols

### 4. Scientific Thinking & Methodologies

Structured frameworks for scientific analysis:

**Analysis Methodologies:**
- **Exploratory Data Analysis** - Automated statistical insights
- **Hypothesis Generation** - Structured frameworks for ideation
- **Peer Review** - Comprehensive evaluation toolkit
- **Scientific Brainstorming** - Creative problem-solving workflows
- **Scientific Critical Thinking** - Rigorous reasoning frameworks
- **Statistical Analysis** - Hypothesis testing and experimental design
- **Scientific Visualization** - Publication-quality figure creation
- **Scientific Writing** - IMRAD format, citation styles, manuscript preparation

**Document Processing:**
- **DOCX** - Word document manipulation and analysis
- **PDF** - Extract, analyze, and generate PDFs
- **PPTX** - PowerPoint presentation creation and editing
- **XLSX** - Excel spreadsheet analysis and reporting

## Usage Guidelines

### When to Use This Skill

Automatically apply this skill when tasks involve:

1. **Literature Research**: Searching PubMed, bioRxiv, analyzing papers
2. **Drug Discovery**: Molecular design, docking, ADMET prediction, structure-activity relationships
3. **Genomics Analysis**: RNA-seq, single-cell, variant calling, genome annotation
4. **Protein Analysis**: Structure prediction, sequence alignment, function annotation
5. **Clinical Research**: Patient data analysis, clinical trials, pharmacogenomics
6. **Data Science**: Statistical analysis, machine learning, visualization
7. **Materials Science**: Crystal structure analysis, property prediction
8. **Lab Integration**: Benchling workflows, LIMS integration, ELN documentation

### Best Practices for Scientific Computing

**1. Always Search for Existing Skills First**
Before attempting any scientific task:
```bash
# Search for relevant skills in the repository
grep -r "keyword" scientific-*/*/SKILL.md
```

**2. Check System Resources**
For computationally intensive tasks:
```python
# Detect available CPU, GPU, memory
# Use parallel processing when appropriate
# Implement chunking for large datasets
```

**3. Follow Scientific Standards**
- Use appropriate statistical tests and corrections
- Document all parameters and random seeds
- Follow domain-specific best practices (e.g., single-cell QC thresholds)
- Cite relevant methods and databases

**4. Handle Data Appropriately**
- Check data formats and validate inputs
- Use memory-efficient approaches (sparse matrices, chunking)
- Implement proper error handling and validation
- Save intermediate results for reproducibility

**5. Provide Context and Interpretation**
- Explain biological/chemical significance of results
- Highlight limitations and assumptions
- Suggest follow-up analyses or validations
- Reference relevant literature when appropriate

## Common Workflow Examples

### End-to-End Drug Discovery Pipeline

```python
"""
Multi-step workflow combining multiple databases and packages:
1. Query ChEMBL for existing inhibitors
2. Analyze SAR with RDKit
3. Generate analogs with Datamol
4. Virtual screening with DiffDock
5. Check COSMIC for relevant mutations
6. Search PubMed for resistance mechanisms
"""

# Example task:
"Find novel EGFR inhibitors with IC50 < 50nM from ChEMBL,
analyze their structure-activity relationships using RDKit,
generate similar molecules with improved properties,
perform virtual screening with DiffDock against AlphaFold
EGFR structure, and check COSMIC for common mutations."
```

### Single-Cell RNA-seq Analysis

```python
"""
Complete single-cell analysis workflow:
1. Load 10X data with Scanpy
2. Quality control and filtering
3. Normalization and feature selection
4. Dimensionality reduction (PCA, UMAP)
5. Clustering and cell type annotation
6. Differential expression with PyDESeq2
7. Pathway enrichment via Reactome/KEGG
8. Integration with public data from Cellxgene Census
"""

# Example task:
"Load this 10X dataset, perform QC, identify cell populations,
run differential expression, and compare with similar tissues
from Cellxgene Census."
```

### Clinical Genomics Variant Interpretation

```python
"""
Variant analysis and clinical reporting:
1. Parse VCF with pysam
2. Annotate with Ensembl
3. Check ClinVar for pathogenicity
4. Query COSMIC for somatic mutations
5. Retrieve gene info from NCBI Gene
6. Check UniProt for protein impact
7. Search PubMed for case reports
8. Generate clinical report with ReportLab
"""

# Example task:
"Analyze this VCF file, annotate all variants, check clinical
significance, and generate a clinical interpretation report."
```

### Multi-Omics Integration

```python
"""
Integrate RNA-seq, proteomics, and metabolomics:
1. Differential expression with PyDESeq2
2. Mass spec analysis with pyOpenMS
3. Metabolite lookup in HMDB
4. Protein interactions via STRING
5. Pathway mapping with KEGG/Reactome
6. Multi-omics correlation with statsmodels
7. ML model building with scikit-learn
"""

# Example task:
"Integrate my RNA-seq, proteomics, and metabolomics data
to identify biomarkers predicting patient outcomes."
```

### Structure-Based Virtual Screening

```python
"""
Discover allosteric modulators:
1. Retrieve AlphaFold structures
2. Identify binding sites with BioPython
3. Search ZINC15 for screening compounds
4. Filter with RDKit drug-likeness rules
5. Molecular docking with DiffDock
6. Property prediction with DeepChem
7. Check PubChem for availability
8. Patent landscape via USPTO
"""

# Example task:
"Find allosteric modulators for this protein-protein interaction
using AlphaFold structures and ZINC compound library."
```

## Installation and Setup

### Prerequisites

**Python Environment:**
```bash
# Recommended: Python 3.10+
python --version

# Create virtual environment
python -m venv scientific-env
source scientific-env/bin/activate  # Linux/Mac
# OR
scientific-env\Scripts\activate  # Windows
```

**Package Installation:**
Packages are installed on-demand based on task requirements. Each skill's SKILL.md file contains specific installation instructions.

**API Keys (when needed):**
Some databases and services require authentication:
- **NCBI E-utilities**: Register for API key at https://www.ncbi.nlm.nih.gov/account/
- **Ensembl REST API**: No key required, but rate-limited
- **ChEMBL**: No authentication required
- **AlphaFold DB**: Public access, no key needed
- **PubChem**: No authentication required

Store API keys securely:
```bash
export NCBI_API_KEY="your_key_here"
# Or in .env file
```

## Reference Documentation Structure

Each skill category contains detailed documentation:

```
scientific-packages/[package-name]/
‚îú‚îÄ‚îÄ SKILL.md                    # Main skill documentation
‚îî‚îÄ‚îÄ references/                 # Detailed reference materials
    ‚îú‚îÄ‚îÄ api_reference.md        # Complete API documentation
    ‚îú‚îÄ‚îÄ workflows_best_practices.md  # Common workflows
    ‚îî‚îÄ‚îÄ [specific-guides].md    # Specialized guides

scientific-databases/[database-name]/
‚îú‚îÄ‚îÄ SKILL.md                    # Query methods and examples
‚îî‚îÄ‚îÄ references/                 # Database-specific documentation
    ‚îú‚îÄ‚îÄ api_endpoints.md        # Available endpoints
    ‚îú‚îÄ‚îÄ query_examples.md       # Common queries
    ‚îî‚îÄ‚îÄ data_models.md          # Response formats
```

**Finding Specific Information:**
```bash
# Search for specific functionality across all skills
grep -r "specific_function" scientific-*/*/SKILL.md

# Search in reference documentation
grep -r "detailed_topic" scientific-*/*/references/

# Find workflow examples
find . -name "workflows_best_practices.md" -exec grep "workflow_name" {} +
```

## Troubleshooting

### Common Issues

**1. Package Import Errors**
```python
# Issue: ModuleNotFoundError
# Solution: Install the specific package
pip install package-name

# Check installed packages
pip list | grep package-name
```

**2. API Rate Limiting**
```python
# Issue: HTTP 429 Too Many Requests
# Solutions:
# - Register for API key to increase limits
# - Implement rate limiting with time.sleep()
# - Batch requests when possible
# - Cache results locally
```

**3. Memory Errors**
```python
# Issue: MemoryError with large datasets
# Solutions:
# - Use sparse matrices (scipy.sparse)
# - Process data in chunks
# - Use backed mode for AnnData
# - Leverage Dask for out-of-core computing
# - Check available resources first
```

**4. Deprecated Functions**
```python
# Issue: DeprecationWarning or removed functions
# Solution: Check package version and update code
pip show package-name  # Check version
# Refer to package's migration guides
```

**5. File Format Issues**
```python
# Issue: Unable to read data files
# Solutions:
# - Verify file format matches expected type
# - Check file corruption (try opening manually)
# - Ensure correct parser/reader function
# - Validate file structure meets specifications
```

### Getting Help

1. **Check Skill Documentation**: Review the specific SKILL.md file
2. **Search References**: Use grep to find relevant information in references/
3. **Verify Installation**: Ensure packages are correctly installed
4. **Check Versions**: Some features require specific package versions
5. **Review Examples**: Look at workflow examples in references/workflows_best_practices.md

## Performance Optimization

### Memory Management

**For Large Datasets:**
```python
# 1. Use sparse matrices for genomics data
from scipy.sparse import csr_matrix
data_sparse = csr_matrix(data)

# 2. Process in chunks
for chunk in pd.read_csv('large_file.csv', chunksize=10000):
    process(chunk)

# 3. Use Dask for distributed computing
import dask.dataframe as dd
df = dd.read_csv('large_file.csv')

# 4. AnnData backed mode
import anndata
adata = anndata.read_h5ad('data.h5ad', backed='r')
```

### Parallel Processing

```python
# 1. Use joblib for parallel tasks
from joblib import Parallel, delayed
results = Parallel(n_jobs=-1)(
    delayed(process_function)(item) for item in items
)

# 2. PyTorch DataLoader for batch processing
from torch.utils.data import DataLoader
loader = DataLoader(dataset, batch_size=32, num_workers=4)

# 3. Dask for large-scale parallelism
import dask
results = dask.compute(*tasks, scheduler='threads')
```

### GPU Acceleration

```python
# Check GPU availability
import torch
print(f"GPU available: {torch.cuda.is_available()}")
print(f"GPU count: {torch.cuda.device_count()}")

# Use GPU when available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)
```

## Advanced Usage Patterns

### Combining Multiple Skills

Many research questions require integrating multiple databases and packages:

**Example: Target Identification Pipeline**
```python
"""
1. Differential expression (PyDESeq2 + GEO data)
2. Literature review (PubMed)
3. Protein information (UniProt)
4. Druggability assessment (Open Targets)
5. Known compounds (ChEMBL)
6. Clinical trials (ClinicalTrials.gov)
7. Patent landscape (USPTO)
"""
```

**Example: Structural Biology Workflow**
```python
"""
1. Sequence retrieval (UniProt)
2. Structure prediction (AlphaFold DB)
3. Experimental structures (PDB)
4. Sequence analysis (BioPython)
5. Docking studies (DiffDock)
6. MD simulation setup
7. Result visualization (Matplotlib)
"""
```

### Reproducible Research

**Best Practices:**
```python
# 1. Set random seeds
import numpy as np
import random
import torch

random.seed(42)
np.random.seed(42)
torch.manual_seed(42)

# 2. Log parameters
params = {
    'date': '2024-01-15',
    'version': pkg.__version__,
    'settings': {...}
}

# 3. Save intermediate results
adata.write('checkpoint_01.h5ad')

# 4. Document data provenance
metadata = {
    'source': 'PubChem',
    'query': 'EGFR inhibitors',
    'date_accessed': '2024-01-15',
    'n_results': 1523
}
```

## Citation and Attribution

When using these skills in research, please cite:

**This Repository:**
```
K-Dense Scientific Skills for Claude (2024)
K-Dense Inc.
https://github.com/K-Dense-AI/claude-scientific-skills
```

**Individual Packages:**
Each package has its own citation requirements. Check the package's documentation or use:
```python
# Many packages provide citation information
import package_name
print(package_name.__citation__)
# Or check: package_name.__version__, package_name.__url__
```

**Databases:**
- **PubMed**: Cite NCBI and specific articles
- **ChEMBL**: Cite ChEMBL database version
- **UniProt**: Cite UniProt Consortium
- **AlphaFold DB**: Cite AlphaFold 2 papers
- See individual database SKILL.md files for specific citations

## License and Usage

**This Skill Collection:**
- License: PolyForm Noncommercial License 1.0.0
- Copyright: K-Dense Inc. (https://k-dense.ai/)
- Free for noncommercial use (research, education)
- Commercial use requires separate license

**Individual Packages:**
Each scientific package has its own license. Check before commercial use:
```bash
# Check package license
pip show package-name | grep License
```

## Related Resources

**Official Repository:**
- GitHub: https://github.com/K-Dense-AI/claude-scientific-skills
- MCP Server: https://github.com/K-Dense-AI/claude-skills-mcp

**K-Dense Enterprise:**
For advanced capabilities and commercial support:
- Website: https://k-dense.ai/
- Enterprise features: Compute infrastructure, custom integrations, dedicated support

**Community:**
- Report issues: https://github.com/K-Dense-AI/claude-scientific-skills/issues
- Contribute: See CONTRIBUTING.md in repository
- Updates: Watch repository for new skills and improvements

## Quick Reference: Available Resources

### By Scientific Domain

**Drug Discovery & Cheminformatics:**
- Databases: ChEMBL, PubChem, ZINC, Open Targets
- Packages: RDKit, DeepChem, DiffDock, Datamol, MedChem, Molfeat, PyTDC, TorchDrug

**Genomics & Bioinformatics:**
- Databases: Ensembl, NCBI Gene, GEO, ENA, GWAS Catalog
- Packages: BioPython, Scanpy, AnnData, scvi-tools, PyDESeq2, pysam, gget, Cellxgene Census

**Proteomics & Structural Biology:**
- Databases: UniProt, PDB, AlphaFold DB, STRING
- Packages: BioPython, pyOpenMS, matchms

**Clinical & Medical:**
- Databases: ClinicalTrials.gov, ClinVar, COSMIC, ClinPGx, FDA
- Packages: pydicom, PyHealth, scikit-survival

**Systems Biology:**
- Databases: KEGG, Reactome, STRING, Metabolomics Workbench, HMDB
- Packages: COBRApy, Arboreto, BIOMNI

**Machine Learning & AI:**
- Packages: PyTorch Lightning, scikit-learn, Transformers, Torch Geometric, SHAP, PyMC, statsmodels

**Data Analysis:**
- Packages: Matplotlib, Seaborn, Polars, Dask, UMAP-learn, ReportLab

### By Task Type

**Literature Review:** PubMed, bioRxiv, USPTO
**Sequence Analysis:** BioPython, pysam, gget, Ensembl
**Single-Cell Analysis:** Scanpy, AnnData, scvi-tools, Cellxgene Census
**Molecular Design:** RDKit, Datamol, MedChem, Molfeat
**Virtual Screening:** DiffDock, DeepChem, PyTDC
**Protein Analysis:** UniProt, AlphaFold DB, PDB, BioPython
**Pathway Analysis:** KEGG, Reactome, STRING
**Clinical Research:** ClinicalTrials.gov, ClinVar, COSMIC
**Statistical Analysis:** statsmodels, PyMC, scikit-learn
**Visualization:** Matplotlib, Seaborn, Scientific Visualization framework

---

**Version:** 1.55.0
**Last Updated:** 2024-01
**Maintainer:** K-Dense Inc.
**Source:** https://github.com/K-Dense-AI/claude-scientific-skills
